{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stop_words\n",
    "\n",
    "class SimpleSummarize:\n",
    "    def __init__(self, filename=None, k=None):\n",
    "        self.txt = None\n",
    "        self.word_tokens = None\n",
    "        self.sent_tokens = None\n",
    "        self.word_freq = None\n",
    "        self.freq_dist = {}\n",
    "        self.sent_scores = {}\n",
    "        self.top_sents = None\n",
    "        self.max_len = 40\n",
    "        self.summary = ''\n",
    "        self.scores = []\n",
    "        self.english_stopwords = set(stopwords.words('english')) | stop_words\n",
    "        if filename and k:\n",
    "            self.load_file_from_disk(filename)\n",
    "            self.tokenize()\n",
    "            self.word_freq_dist()\n",
    "            self.score_sentences()\n",
    "            self.summarize(k)\n",
    "    \n",
    "    def load_file_from_disk(self, filename):\n",
    "        with open(filename, \"r\") as file:\n",
    "            self.txt = file.read().replace(\"\\n\", \" \")\n",
    "            self.txt = self.txt.replace(\"\\'\",\"\")\n",
    "    \n",
    "    def tokenize(self):\n",
    "        self.word_tokens = self.tokenizer(self.txt)\n",
    "        #self.sent_tokens = self.simple_sent_tokenizer(self.txt)\n",
    "        self.sent_tokens = sent_tokenize(self.txt)\n",
    "\n",
    "    def simple_sent_tokenizer(self, s):\n",
    "        sents = []\n",
    "        for sent in s.split('.'):\n",
    "            sents.append(sent.strip())\n",
    "        return sents\n",
    "        \n",
    "    def tokenizer(self,txt):\n",
    "        txt = txt.lower()\n",
    "        word_tokens = word_tokenize(txt.lower())\n",
    "        word_tokens = [w for w in word_tokens if w not in self.english_stopwords and re.match('[a-zA-Z-][a-zA-Z-]{2,}', w)]\n",
    "        return word_tokens\n",
    "    \n",
    "    def word_freq_dist(self):\n",
    "        self.word_freq = nltk.FreqDist(self.word_tokens)\n",
    "        most_freq_count = max(self.word_freq.values())\n",
    "        for k,v in self.word_freq.items():\n",
    "            self.freq_dist[k] = v/most_freq_count\n",
    "    \n",
    "    def score_sentences(self):\n",
    "        for sent in self.sent_tokens:\n",
    "            words = self.tokenizer(sent)\n",
    "            for word in words:\n",
    "                if word.lower() in self.freq_dist.keys():\n",
    "                    if len(words) < self.max_len:\n",
    "                        # if key does not exist add it and the freq_dist for the first word\n",
    "                        if sent not in self.sent_scores.keys():\n",
    "                            self.sent_scores[sent] = self.freq_dist[word.lower()]\n",
    "                        else: \n",
    "                            # the key exists and we just add the freq_dist of the following words. \n",
    "                            # We are just summing up the freq_dists for the sentence\n",
    "                            self.sent_scores[sent] += self.freq_dist[word.lower()]\n",
    "    \n",
    "    def summarize(self, k):\n",
    "        self.top_sents = Counter(self.sent_scores)\n",
    "        for t in self.top_sents.most_common(k):\n",
    "            self.summary += t[0].strip()+'. '\n",
    "            self.scores.append((t[1],t[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Judiciary Committee hearing is the latest sign that House Democrats are moving forward with impeachment proceedings against the President following the two-month investigation led by the House Intelligence Committee into allegations that Trump pushed Ukraine to investigate his political rivals while a White House meeting and $400 million in security aid were withheld from Kiev.. The House Judiciary Committee has invited President Donald Trump or his counsel to participate in the panels first impeachment hearing next week as the House moves another step closer to impeaching the President.. READ: Judiciary Chairman&#39;s invite to Trump and his lawyers to take part in upcoming impeachment hearings The hearing announcement comes as the Intelligence Committee plans to release its report summarizing the findings of its investigation to the House Judiciary Committee soon after Congress returns from its Thanksgiving recess next week.. '"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# foo = SimpleSummarize()\n",
    "# foo.load_file_from_disk(\"CNNImpeachmentArticle.txt\")\n",
    "# foo.tokenize()\n",
    "# foo.word_freq_dist()\n",
    "# foo.score_sentences()\n",
    "# foo.summarize(3)\n",
    "# foo.summary\n",
    "foo = SimpleSummarize(filename=\"CNNImpeachmentArticle.txt\", k=3)\n",
    "foo.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Extraction from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = 'impeachment_data/20191203_-_full_report___hpsci_impeachment_inquiry_-_20191203.pdf'\n",
    "pd_file_obj = open(pdf, 'rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(pd_file_obj)\n",
    "num_pages = pdf_reader.getNumPages()\n",
    "full_text = ''\n",
    "for p in range(num_pages):\n",
    "    full_text = full_text + pdf_reader.getPage(p).extractText().strip().replace('\\n','')\n",
    "with open('impeachment_data/trump_impeachment_inquiry.txt', 'w+') as file:\n",
    "    file.write(full_text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE TRUMP-UKRAINE  IMPEACHMENT INQUIRY REPORT   Report of the House Permanent Select Committee on Intelligence, Pursuant to H. Res. 660 in Consultation with the  House Committee on Oversight and Reform and the  House Committee on Foreign Affairs   December 20192  House Permanent Select Committee on Intelligence  Rep. Adam B. Schiff (CA), Chairman  Rep. Jim Himes (CT) Rep. Terri Sewell (AL) Rep. AndrÃ© Carson (IN)  Rep. Jackie Speier (CA) Rep. Mike Quigley (IL)  Rep. Eric Swalwell (CA)  Rep. Joaquin Castro (TX)  Rep. Denny Heck (WA)  Rep. Peter Welch (VT)  Rep. Sean Patrick Maloney (NY)  Rep. Devin Nunes (CA), Ranking Member  Rep. Mike Conaway (TX)  Rep. Michael Turner (OH)  Rep. Brad Wenstrup (OH)  Rep. Chris Stewart (UT)  Rep. Elise Stefanik (NY)  Rep. Will Hurd (TX)  Rep. John Ratcliffe (TX) Rep. Jim Jordan (OH) Rep. Val Demings (FL) Rep. Raja Krishnamoorthi (IL)  Majority Staff Timothy S. Bergreen, Staff Director  Daniel S. Goldman, Director of Investigations Maher Bitar, General Cou'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E. Cummings, House Committee on Oversight and Reform, and Chairman Adam B. Schiff, House Permanent Select Committee on Intelligence, the same day).. 77 Letter from Pat A. Cipollone, Counsel to the President, The White House, to House Speaker Nancy Pelosi, Chairman Adam B. Schiff, House Permanent Select Committee on Intelligence, Chairman Eliot L. Engel, House Committee on Foreign Affairs Committee, and Chairman Elijah E. Cummings, House Committee on Oversight and Reform (Oct. 8, 2019) (online at www.whitehouse.gov/wp-content/uploads/2019/10/PAC-Letter-10.08.2019.pdf).. 88 Letter from Pat A. Cipollone, Counsel to the President, The White House, to House Speaker Nancy Pelosi, Chairman Adam B. Schiff, House Permanent Select Committee on Intelligence, Chairman Eliot L. Engel, House Committee on Foreign Affairs Committee, and Chairman Elijah E. Cummings, House Committee on Oversight and Reform (Oct. 8, 2019) (online at www.whitehouse.gov/wp-content/uploads/2019/10/PAC-Letter-10.08.2019.pdf).. '"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impeachment_summary = SimpleSummarize(filename=\"impeachment_data/trump_impeachment_inquiry.txt\", k=3)\n",
    "impeachment_summary.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24.507658643326028,\n",
       "  'E. Cummings, House Committee on Oversight and Reform, and Chairman Adam B. Schiff, House Permanent Select Committee on Intelligence, the same day).'),\n",
       " (10.921225382932166,\n",
       "  '77 Letter from Pat A. Cipollone, Counsel to the President, The White House, to House Speaker Nancy Pelosi, Chairman Adam B. Schiff, House Permanent Select Committee on Intelligence, Chairman Eliot L. Engel, House Committee on Foreign Affairs Committee, and Chairman Elijah E. Cummings, House Committee on Oversight and Reform (Oct. 8, 2019) (online at www.whitehouse.gov/wp-content/uploads/2019/10/PAC-Letter-10.08.2019.pdf).'),\n",
       " (10.921225382932166,\n",
       "  '88 Letter from Pat A. Cipollone, Counsel to the President, The White House, to House Speaker Nancy Pelosi, Chairman Adam B. Schiff, House Permanent Select Committee on Intelligence, Chairman Eliot L. Engel, House Committee on Foreign Affairs Committee, and Chairman Elijah E. Cummings, House Committee on Oversight and Reform (Oct. 8, 2019) (online at www.whitehouse.gov/wp-content/uploads/2019/10/PAC-Letter-10.08.2019.pdf).')]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impeachment_summary.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "https://nlpforhackers.io/topic-modeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Algorithms\n",
    "\n",
    "There are several algorithms for doing topic modeling. The most popular ones include\n",
    "\n",
    "LDA â Latent Dirichlet Allocation â The one weâll be focusing in this tutorial. Its foundations are Probabilistic Graphical Models\n",
    "\n",
    "LSA or LSI â Latent Semantic Analysis or Latent Semantic Indexing â Uses Singular Value Decomposition (SVD) on the Document-Term Matrix. Based on Linear Algebra\n",
    "\n",
    "NMF â Non-Negative Matrix Factorization â Based on Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gensim for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "from gensim import models, corpora, similarities\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 2\n",
    "STOPWORDS = set(stopwords.words('english')) | stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files_from_disk(data_dir):\n",
    "    text_data_list = []\n",
    "    file_list = glob(pathname=data_dir + '/*txt')\n",
    "    for file in file_list: \n",
    "        with open(file, \"r\") as f:\n",
    "            text_data_list.append(f.read())\n",
    "    return text_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    cleaned_text = [t for t in tokenized_text if t not in STOPWORDS and re.match('[a-zA-Z\\-][a-zA-Z\\-]{2,}', t)]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_data = load_files_from_disk('impeachment_data/')\n",
    "len(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gensim we need to tokenize the data and filter out stopwords\n",
    "tokenized_data = []\n",
    "for text in article_data:\n",
    "    tokenized_data.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Gensim Dictionary - assocation word to numeric id\n",
    "dictionary = corpora.Dictionary(tokenized_data)\n",
    "# for k,v in dictionary.items():\n",
    "#     print((k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the collection of texts to a numerical form\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)\n",
    "\n",
    "#Build the LSI model\n",
    "lsi_model = models.LsiModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "LDA Model:\n",
      "Topic #0: 0.034*\"president\" + 0.018*\"house\" + 0.016*\"trump\" + 0.013*\"ambassador\" + 0.011*\"ukraine\"\n",
      "Topic #1: 0.025*\"president\" + 0.017*\"house\" + 0.016*\"ambassador\" + 0.013*\"committee\" + 0.012*\"ukraine\"\n",
      "===================================================================================================================\n",
      "LSI Model:\n",
      "Topic #0: 0.582*\"president\" + 0.295*\"house\" + 0.269*\"ambassador\" + 0.225*\"trump\" + 0.193*\"ukraine\"\n",
      "Topic #1: -0.543*\"president\" + 0.286*\"committee\" + 0.246*\"dep\" + 0.232*\"house\" + 0.185*\"chairman\"\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 115)\n",
    "print(\"LDA Model:\")\n",
    "for idx in range(NUM_TOPICS):\n",
    "    print(\"Topic #%s:\"%idx, lda_model.print_topic(idx,5))\n",
    "print(\"=\" * 115)\n",
    "print(\"LSI Model:\")\n",
    "for idx in range(NUM_TOPICS):\n",
    "    print(\"Topic #%s:\"%idx, lsi_model.print_topic(idx,5))\n",
    "print(\"=\" * 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 8.212948210731929), (1, 3.293606890748997)]\n",
      "[(6, 0.9864905)]\n"
     ]
    }
   ],
   "source": [
    "t = \"\"\"\n",
    "The report puts Trump personal lawyer Rudy Giuliani at the center of a scheme to force out the U.S. ambassador to Ukraine and pressure that countryâs government to investigate Joe Bidenâs family and a conspiracy theory that Ukraine interfered in the 2016 U.S. election.\n",
    "The House obtained AT&T call records showing Giuliani in contact with phone numbers associated with the White House, the Office of Management and Budget, top Intelligence Committee Republican Devin Nunes, and Giuliani associate Lev Parnas. The report doesnât say who in the White House or OMB participated in the calls.\n",
    "The calls and texts were made during the time period when Giuliani was publicly discussing his efforts to pursue investigations into the Bidens and a conspiracy theory about Ukrainian interference in the 2016 election.\n",
    "House Intelligence Chairman Adam Schiff said the call records show that âthere was considerable coordination among the parties including the White Houseâ in a smear campaign against then-U.S. Ambassador Marie Yovanovitch.\n",
    "The committee also found Giuliani in contact on Aug. 8 with phone numbers associated with the White House amid negotiations with Ukrainian officials about announcing investigations. The records also showed European Union Ambassador Gordon Sondland in contact with White House and OMB phone numbers on Aug. 9.\n",
    "One of the Sondland calls came minutes before a text message he sent saying that he thought Trump strongly wanted the âdeliverable.â Sondland later said that referred to an announcement by Ukraine of investigations sought by Trump and Giuliani.\n",
    "\"\"\"\n",
    "bow = dictionary.doc2bow(clean_text(t))\n",
    "print(lsi_model[bow])\n",
    "print(lda_model[bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_index = similarities.MatrixSimilarity(lda_model[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = lda_index[lda_model[bow]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.99974495), (1, 0.034893364)]\n"
     ]
    }
   ],
   "source": [
    "print(sims[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME  \n",
      "The Trump-Ukraine Impeachment Inquiry Report\n",
      "\n",
      "The impeachment inquiry into Donald J. Trump, the 45th President of the United States, uncovered a months-long effort by President Trump to use the powers of his office to solicit foreign interference on his behalf in the 2020 election.  As described in this executive summary and the report that follows, President Trumpâs scheme subverted U.S. foreign policy toward Ukraine and undermined our national security in favor of two politically motivated investigations that would help his presidential reelection campaign.  The President demanded that the newly-elected Ukrainian president, Volodymyr Zelensky, publicly announce investigations into a political rival that he apparently feared the most, former Vice President Joe Biden, and into a discredited theory that it was Ukraine, not Russia, that interfered in the 2016 presidential election.  To compel the Ukrainian President to do his political bidding, President Trump conditioned two offi\n"
     ]
    }
   ],
   "source": [
    "document_id, similarity = sims[1]\n",
    "print(article_data[document_id][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn for Topic Modeling\n",
    "\n",
    "scikit-learn offers an NMF model in addition to LDA and LSI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
